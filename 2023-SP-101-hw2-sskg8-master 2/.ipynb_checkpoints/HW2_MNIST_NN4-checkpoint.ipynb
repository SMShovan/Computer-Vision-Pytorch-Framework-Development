{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a327e15",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c736faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numba import cuda\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd7b03",
   "metadata": {},
   "source": [
    "### 2. Import from mlcblab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9169c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlcvlab.models.nn4 import NN4\n",
    "from mlcvlab.nn.losses import l2\n",
    "from mlcvlab.optim.sgd import SGD\n",
    "from mlcvlab.optim.sync_sgd import sync_sgd\n",
    "# TODO: Import all the necessary code from mlcvlab package as you need... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88408184",
   "metadata": {},
   "source": [
    "### 3. Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f55896",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f6cc05",
   "metadata": {},
   "source": [
    "### 4. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fade33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    x, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "    y = np.asarray(y, dtype=np.float64)\n",
    "    return x, y\n",
    "\n",
    "def prepare_data(x, y):\n",
    "    y = np.apply_along_axis(lambda num: num % 2 == 0, 0, y).astype(\"int\")\n",
    "    return x, y\n",
    "\n",
    "def split_train_test(x,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=10000, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def minibatch(X_train,y_train,K):\n",
    "\n",
    "    X_train_batches = []\n",
    "    y_train_batches = []\n",
    "    y_train=y_train.reshape(-1,1)\n",
    "    \n",
    "    assert len(X_train) == len(y_train), \"Input and output data should have the same length.\"\n",
    "    data_size = len(X_train)\n",
    "    indices = np.arange(data_size)\n",
    "    np.random.shuffle(indices)#random shuffling for distributed data\n",
    "\n",
    "    for start_idx in range(0, data_size, K):\n",
    "        end_idx = min(start_idx + K, data_size)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "        mini_batch_x=X_train[batch_indices,:]\n",
    "        mini_batch_y=y_train[batch_indices,:]\n",
    "        X_train_batches.append(mini_batch_x)\n",
    "        y_train_batches.append(mini_batch_y)\n",
    "\n",
    "    return X_train_batches, y_train_batches\n",
    "\n",
    "def initialize_model():\n",
    "    #TODO (Can use the similar approach used in HW1)\n",
    "    # e.g. He Initialization for W0-W2, Xavier Initialization for W3\n",
    "    # Also, initialize your model with a dropout parameter of 0.25 and use_batchnorm being true.\n",
    "    \n",
    "    #Xavier Weight Initialization\n",
    "    n_in_1= 300\n",
    "    n_out_1=784\n",
    "    std_1 = np.sqrt(2) / np.sqrt(n_in_1 + n_out_1)\n",
    "    W1 = np.random.normal(loc=0, scale=std_1, size=(n_in_1, n_out_1)) #(300,784)\n",
    "    \n",
    "    n_2 = 150\n",
    "    std_2 = np.sqrt(2) / np.sqrt(n_2 + n_in_1)\n",
    "    W2 = np.random.normal(loc=0, scale=std_2, size=(n_2, n_in_1)) #(150,300)\n",
    "    \n",
    "    n_3 = 50\n",
    "    std_3 = np.sqrt(2) / np.sqrt(n_3 + n_2)\n",
    "    W3 = np.random.normal(loc=0, scale=std_1, size=(n_3, n_2)) #(50,150)\n",
    "    \n",
    "    n_4 = 1\n",
    "    std_4 = np.sqrt(2) / np.sqrt(n_4 + n_3)\n",
    "    W4 = np.random.normal(loc=0, scale=std_1, size=(n_4, n_3)) #(1,50)\n",
    "    \n",
    "    print(f\"Size of W1 : {W1.shape}, Size of W2 : {W2.shape}, Size of W3 : {W3.shape}, Size of W4 : {W4.shape}\")\n",
    "    four_layer_nn  = NN4(use_batchnorm=True, dropout_param=0.25)\n",
    "    four_layer_nn.layers[0].W = W1\n",
    "    four_layer_nn.layers[1].W = W2\n",
    "    four_layer_nn.layers[2].W = W3\n",
    "    four_layer_nn.layers[3].W = W4\n",
    "\n",
    "    return four_layer_nn\n",
    "\n",
    "def train_model(model, X_train_batches, y_train_batches):\n",
    "    print(\"The gradient of emperical risk for W1, W2, W3 and W4:\")\n",
    "    griddim = (64,64)\n",
    "    blockdim = (256,256)\n",
    "\n",
    "    stream = cuda.stream()\n",
    "\n",
    "    d_X_train_batches = cuda.to_device(X_train_batches, stream=stream)\n",
    "    d_y_train_batches = cuda.to_device(y_train_batches, stream=stream)\n",
    "\n",
    "    model_sync = sync_sdg[griddim, blockdim](model, d_X_train_batches, d_y_train_batches)\n",
    "    model_sync = model_sync.copy_to_host()\n",
    "\n",
    "    model_async = async_sgd[griddim, blockdim, stream](model, d_X_train_batches, d_y_train_batches)\n",
    "    model_async = model_async.copy_to_host(stream=stream)\n",
    "\n",
    "    return model_async, model_sync\n",
    "\n",
    "def test_model(model, X_test, y_test):\n",
    "    \n",
    "    y_hat = model.nn4(X_test, mode='test')[0].T\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "    error = np.round_(np.abs(y_test - y_hat), 2)\n",
    "    indicator_fn = np.greater(error, np.zeros(error.shape)).astype('float')\n",
    "\n",
    "    accuracy = np.mean(indicator_fn) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4fe07",
   "metadata": {},
   "source": [
    "### 5. Run the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minibatch size\n",
    "K = 100\n",
    "\n",
    "#load data\n",
    "x, y = load_dataset()\n",
    "print(\"Dataset imported successfully\")\n",
    "\n",
    "#prepare data\n",
    "x, y = prepare_data(x,y)\n",
    "print(\"Data prepared successfully\")\n",
    "\n",
    "# split data set\n",
    "X_train, X_test, y_train, y_test = split_train_test(x,y)\n",
    "print(\"Dataset Splitted successfully\")\n",
    "\n",
    "#initialize model\n",
    "model = initialize_model()\n",
    "print(\"NN4 successfully implemented\")\n",
    "\n",
    "#dividing data into mini batches\n",
    "X_train_batches, y_train_batches = minibatch(X_train, y_train, K)\n",
    "print(\"Data successfully split into mini batches\")\n",
    "\n",
    "#training model\n",
    "sgd = SGD(model, X_train_batches, y_train_batches, lr=0.01, R=50)\n",
    "print(f\"Completed training with SGD, now testing...\")\n",
    "\n",
    "#testing model\n",
    "accuracy = test_model(sgd, X_test, y_test)\n",
    "print(f\"Completed testing model using SGD - Accuracy : {accuracy}\")\n",
    "\n",
    "#training model with cuda\n",
    "async_model, sync_model = train_model(model, X_train_batches, y_train_batches)\n",
    "print(f\"Completed training model - final W : {final_W}\")\n",
    "print(f\"Completed training, now testing...\")   \n",
    "\n",
    "#testing model\n",
    "# accuracy_async = test_model(model_async, X_test, y_test)\n",
    "# print(f\"Completed testing model using asynchronous SGD - Accuracy : {accuracy_async}\")   \n",
    "\n",
    "accuracy_sync = test_model(sync_model, X_test, y_test)\n",
    "print(f\"Completed testing model using synchronous SGD - Accuracy : {accuracy_sync}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e0e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
